from __future__ import annotations

from abc import abstractmethod, ABC
import ast
import time
from collections.abc import Sequence # Keep this for compatibility if needed elsewhere
import copy
from typing import Any, Type, Optional
import numpy as np # For score comparison tolerance

# Local Imports
from . import code_manipulation
from . import programs_database
from . import efficiency_utils # Import the efficiency utils
from . import profile # For type hinting profiler

# Define _FunctionLineVisitor and _trim_function_body (copied from original)
class _FunctionLineVisitor(ast.NodeVisitor):
    """Visitor that finds the last line number of a function with a given name."""
    def __init__(self, target_function_name: str) -> None:
        self._target_function_name: str = target_function_name
        self._function_end_line: int | None = None

    def visit_FunctionDef(self, node: Any) -> None: # pylint: disable=invalid-name
        """Collects the end line number of the target function."""
        if node.name == self._target_function_name:
            # Use end_lineno for Python 3.8+
            self._function_end_line = node.end_lineno if hasattr(node, 'end_lineno') else node.lineno # Fallback might be inaccurate
        self.generic_visit(node)

    @property
    def function_end_line(self) -> int:
        """Line number of the final line of function `target_function_name`."""
        if self._function_end_line is None:
             # Fallback or error if function not found or end_lineno unavailable
             raise ValueError("Could not determine function end line.")
        return self._function_end_line

def _trim_function_body(generated_code: str) -> str:
    """Extracts the body of the generated function, trimming anything after it."""
    if not generated_code: return ''
    # Add header temporarily for parsing
    code = f'def fake_function_header():\n{generated_code}'
    tree = None
    original_lines = code.splitlines()
    current_lines = list(original_lines)

    while tree is None:
        if not current_lines: return '' # Failed to parse anything
        code_to_parse = '\n'.join(current_lines)
        try:
            tree = ast.parse(code_to_parse)
        except SyntaxError as e:
            # Determine the failing line more carefully relative to the *current* lines
            fail_line_index = e.lineno - 1 if e.lineno is not None else len(current_lines) -1
            if fail_line_index < 0: fail_line_index = 0 # Ensure index is valid
            # Trim from the failing line downwards
            current_lines = current_lines[:fail_line_index]
        except Exception: # Catch other potential parsing errors
             return '' # Cannot parse, return empty

    if not tree or not current_lines: return ''

    # Find the end line of the *successfully parsed* fake function
    try:
        visitor = _FunctionLineVisitor('fake_function_header')
        visitor.visit(tree)
        # Lines belonging to the function body (relative to the successfully parsed code)
        # Start after the 'def' line (index 0), end at the found end_lineno
        body_lines = current_lines[1:visitor.function_end_line]
        return '\n'.join(body_lines) + '\n\n' # Add trailing newlines for consistency
    except ValueError: # If fake_function_header wasn't found (shouldn't happen)
        return '' # Failed to extract body


def _sample_to_program(
        generated_code: str,
        version_generated: int | None,
        template: code_manipulation.Program,
        function_to_evolve: str,
) -> tuple[code_manipulation.Function, str]:
    """Compiles the sample into a Function object and the full runnable program string."""
    body = _trim_function_body(generated_code)
    # Rename recursive calls if a version was generated by evolutionary process
    if version_generated is not None:
        body = code_manipulation.rename_function_calls(
            code=body,
            source_name=f'{function_to_evolve}_v{version_generated}',
            target_name=function_to_evolve # Rename back to the base name
        )

    program = copy.deepcopy(template)
    try:
        evolved_function = program.get_function(function_to_evolve)
        evolved_function.body = body # Assign the processed body
    except ValueError as e:
         # Re-raise with more context if function_to_evolve not found in template
         raise ValueError(f"Function '{function_to_evolve}' not found in template. Error: {e}") from e

    return evolved_function, str(program)


class Sandbox(ABC):
    """Abstract base class for executing generated code safely."""
    @abstractmethod
    def run(
            self,
            program: str,
            function_to_run: str,
            function_to_evolve: str,
            inputs: Any,
            test_input: Any, # Can be key, index, or actual input data
            timeout_seconds: int,
            **kwargs # Allow passing flags like is_fingerprint_run
    ) -> tuple[Any, bool]:
        """
        Executes the specified function within the program string.

        Args:
            program: The complete Python code as a string.
            function_to_run: The name of the function to call (e.g., 'evaluate').
            function_to_evolve: The name of the function being evolved (for potential optimizations).
            inputs: The full dataset or context.
            test_input: The specific input (or identifier) for this run.
            timeout_seconds: Maximum execution time.
            **kwargs: Additional arguments, like 'is_fingerprint_run'.

        Returns:
            A tuple containing:
            - The result returned by `function_to_run`.
            - A boolean indicating if execution succeeded (True) or failed/timed out (False).
        """
        raise NotImplementedError('Must provide a sandbox for executing untrusted code.')


def _calls_ancestor(program: str, function_to_evolve: str) -> bool:
    """Checks if the evolved function calls older versions of itself."""
    try:
        called_functions = code_manipulation.get_functions_called(program)
        for name in called_functions:
            # If the base name is `priority`, look for calls like `priority_v0`, `priority_v1`, etc.
            if name.startswith(f'{function_to_evolve}_v'):
                return True
    except Exception:
         # If parsing fails (e.g., invalid Python code), assume it might call an ancestor to be safe? Or treat as invalid?
         # Let's assume parsing failure means the code is bad anyway, so return False.
         return False
    return False


class Evaluator:
    """
    Analyzes functions generated by LLMs, incorporating duplicate checking
    and optional cache hit validation.
    """

    def __init__(
            self,
            database: programs_database.ProgramsDatabase,
            template: code_manipulation.Program,
            function_to_evolve: str,
            function_to_run: str,
            inputs: Sequence[Any], # Full input set
            timeout_seconds: int = 30,
            sandbox_class: Type[Sandbox] = Sandbox,
            # --- Efficiency Components ---
            duplicate_checker: Optional[efficiency_utils.DuplicateChecker] = None,
            use_ast_hash_check: bool = True,
            use_fingerprint_check: bool = True,
            fingerprint_inputs: Optional[Sequence[Any]] = None,
            fingerprint_timeout_seconds: int = 5,
            # --- Validation Flag ---
            validate_cache_hits: bool = False
    ):
        self._database = database
        self._template = template
        self._function_to_evolve = function_to_evolve
        self._function_to_run = function_to_run
        self._inputs = inputs # Full input set
        self._timeout_seconds = timeout_seconds
        self._sandbox = sandbox_class()
        # Store efficiency components and flags
        self._duplicate_checker = duplicate_checker
        self._use_ast_hash_check = use_ast_hash_check
        self._use_fingerprint_check = use_fingerprint_check
        self._fingerprint_inputs = fingerprint_inputs
        self._fingerprint_timeout_seconds = fingerprint_timeout_seconds
        self._validate_cache_hits = validate_cache_hits
        self._profiler_instance: Optional[profile.Profiler] = None # To store profiler passed in analyse


    def _perform_full_evaluation(
        self,
        program_str: str,
        new_function: code_manipulation.Function # For potential error reporting
        ) -> Tuple[Optional[programs_database.ScoresPerTest], float]:
        """Performs full evaluation, returning scores and time."""
        eval_start_time = time.time()
        scores_per_test: programs_database.ScoresPerTest = {}
        evaluation_success = False

        if _calls_ancestor(program_str, self._function_to_evolve):
            print(f"=> Evaluation Skipped (Sample {new_function.global_sample_nums}): Program calls ancestor.")
            eval_time = time.time() - eval_start_time
            return None, eval_time # Return None for scores if ancestor call detected

        for current_input in self._inputs:
            # Use a shorter timeout for individual runs within the full eval? Or stick to the main one?
            # Let's stick to the main self._timeout_seconds for full evaluation robustness.
            test_output, runs_ok = self._sandbox.run(
                program=program_str,
                function_to_run=self._function_to_run,
                function_to_evolve=self._function_to_evolve,
                inputs=self._inputs,
                test_input=current_input,
                timeout_seconds=self._timeout_seconds,
                is_fingerprint_run=False # Explicitly mark as full run
            )

            if runs_ok and test_output is not None:
                # Check if the output is a valid score type
                if not isinstance(test_output, (int, float)):
                    print(f"=> Evaluation Failed (Sample {new_function.global_sample_nums}): Non-numeric output '{test_output}' for input '{current_input}'")
                    scores_per_test = {} # Discard previous scores
                    evaluation_success = False
                    break # Stop evaluating further inputs
                # Handle NaN/Infinity if necessary, depending on problem domain
                if isinstance(test_output, float) and not np.isfinite(test_output):
                    print(f"=> Evaluation Failed (Sample {new_function.global_sample_nums}): Non-finite score '{test_output}' for input '{current_input}'")
                    scores_per_test = {}
                    evaluation_success = False
                    break
                scores_per_test[current_input] = test_output
                evaluation_success = True # Mark as potentially successful if loop continues
            else:
                # Sandbox run failed or timed out for this input
                # print(f"=> Evaluation Failed (Sample {new_function.global_sample_nums}): Sandbox run failed for input '{current_input}'")
                scores_per_test = {}
                evaluation_success = False
                break # Stop evaluating

        eval_time = time.time() - eval_start_time
        # Return scores only if evaluation completed successfully for all inputs
        return scores_per_test if evaluation_success else None, eval_time


    def analyse(
            self,
            sample: str,
            island_id: int | None,
            version_generated: int | None,
            **kwargs
    ) -> None:
        """Compiles, checks duplicates, optionally validates, evaluates if novel."""

        # 1. Initial Setup (Profiler, Timers, Sample Info)
        self._profiler_instance = kwargs.get('profiler', None)
        global_sample_nums = kwargs.get('global_sample_nums', None)
        sample_time = kwargs.get('sample_time', None) # Time to generate the sample
        total_check_time = 0.0
        total_evaluate_time = 0.0
        is_duplicate = False
        cached_score: Optional[float] = None
        ast_hash: Optional[str] = None
        fingerprint_hash: Optional[str] = None

        # 2. Compile Sample
        try:
            new_function, program_str = _sample_to_program(
                sample, version_generated, self._template, self._function_to_evolve)
            # Assign sample number to the function object early for logging context
            if global_sample_nums is not None: new_function.global_sample_nums = global_sample_nums
            if sample_time is not None: new_function.sample_time = sample_time

        except Exception as e:
            # print(f"=> Compile Failed (Sample {global_sample_nums}): {e}")
            if self._profiler_instance:
                fail_func = code_manipulation.Function(name=f"failed_compile_{global_sample_nums}", args="", body=sample)
                fail_func.global_sample_nums = global_sample_nums
                fail_func.score = None
                fail_func.sample_time = sample_time
                fail_func.evaluate_time = 0 # No eval/check time
                self._profiler_instance.register_function(fail_func)
            return # Stop processing

        # 3. Perform Duplicate Check (if checker is enabled)
        if self._duplicate_checker:
            # Determine if fingerprint check can run
            fp_inputs_available = self._fingerprint_inputs is not None
            can_run_fp_check = self._use_fingerprint_check and fp_inputs_available

            is_duplicate, cached_score, ast_hash, fingerprint_hash, check_time = \
                self._duplicate_checker.check_program(
                    function_body=new_function.body, program_str=program_str,
                    sandbox=self._sandbox, function_to_run=self._function_to_run,
                    function_to_evolve=self._function_to_evolve, full_inputs=self._inputs,
                    fingerprint_inputs=self._fingerprint_inputs,
                    fingerprint_timeout_seconds=self._fingerprint_timeout_seconds,
                    use_ast_check=self._use_ast_hash_check,
                    use_fingerprint_check=can_run_fp_check
                )
            total_check_time = check_time


        # 4. Handle Cache Hit OR Proceed to Full Evaluation
        final_scores_per_test: Optional[programs_database.ScoresPerTest] = None
        final_score: Optional[float] = None
        processed_as_cache_hit = False # Flag for profiler registration

        if is_duplicate:
            # ----- CACHE HIT PATH -----
            processed_as_cache_hit = True
            hit_type = "AST" if fingerprint_hash is None else "Fingerprint"
            print(f"\n=> Cache Hit ({hit_type}) | Sample {global_sample_nums} | AST: {ast_hash} | FP: {fingerprint_hash} | Cached Score: {cached_score}")

            # 4.1 OPTIONAL: Validate Cache Hit
            if self._validate_cache_hits:
                print(f"=> Validating Cache Hit for Sample {global_sample_nums}...")
                # Perform full evaluation for validation
                validation_scores, validation_time = self._perform_full_evaluation(program_str, new_function)
                total_evaluate_time = validation_time # Validation time is the evaluation time here

                if validation_scores is not None:
                    actual_score = programs_database._reduce_score(validation_scores)
                    final_scores_per_test = validation_scores # Use actual scores
                    final_score = actual_score

                    # Log comparison
                    score_diff = abs(actual_score - cached_score) if cached_score is not None else float('inf')
                    tolerance = 1e-6 # Tolerance for float comparison
                    print(f"=> Validation Result Sample {global_sample_nums}:")
                    print(f"  - Actual Score   : {actual_score:.6f}")
                    print(f"  - Cached Score   : {cached_score:.6f}" if cached_score is not None else "N/A (AST Hit)")
                    if cached_score is not None:
                        print(f"  - Abs Difference : {score_diff:.6f} {'(MATCH)' if score_diff < tolerance else '(DIFFER)'}")
                    # Update cache with actual score if validation was successful? Potentially corrects bad cache entries.
                    if self._duplicate_checker:
                         # Ensure hashes were calculated during check
                         if ast_hash is None and self._use_ast_hash_check: ast_hash = efficiency_utils.calculate_ast_hash(new_function.body)
                         if fingerprint_hash is None and self._use_fingerprint_check and self._fingerprint_inputs: fingerprint_hash, _, _ = efficiency_utils.calculate_fingerprint(program_str=program_str, sandbox=self._sandbox, function_to_run=self._function_to_run, function_to_evolve=self._function_to_evolve, full_inputs=self._inputs, fingerprint_inputs=self._fingerprint_inputs, timeout_seconds=self._fingerprint_timeout_seconds)
                         # Register with validated score
                         self._duplicate_checker.register_program(ast_hash, fingerprint_hash, actual_score)

                else:
                    # Validation run failed
                    print(f"=> Validation Failed for Sample {global_sample_nums}: Program error during full evaluation.")
                    final_scores_per_test = None # No valid scores
                    final_score = None

            # 4.2 Standard Cache Hit Logic (if validation OFF)
            else:
                if cached_score is not None:
                    # Fingerprint Hit: Use cached score
                    final_scores_per_test = {'cached': cached_score} # Use dummy dict for db
                    final_score = cached_score
                    total_evaluate_time = 0 # No evaluation performed
                else:
                    # AST Hit: Treat as invalid/discarded program
                    final_scores_per_test = None
                    final_score = None
                    total_evaluate_time = 0

        else:
            # ----- FULL EVALUATION PATH (Not a duplicate) -----
            processed_as_cache_hit = False
            # Perform full evaluation
            scores_from_eval, eval_time = self._perform_full_evaluation(program_str, new_function)
            total_evaluate_time = eval_time

            if scores_from_eval is not None:
                final_scores_per_test = scores_from_eval
                final_score = programs_database._reduce_score(scores_from_eval)
                # Add successfully evaluated program to caches if enabled
                if self._duplicate_checker:
                    # Recalculate hashes if needed (should have been calculated if checks on)
                    if ast_hash is None and self._use_ast_hash_check:
                         ast_hash = efficiency_utils.calculate_ast_hash(new_function.body)
                    if fingerprint_hash is None and self._use_fingerprint_check and self._fingerprint_inputs:
                         fingerprint_hash, _, _ = efficiency_utils.calculate_fingerprint(program_str=program_str, sandbox=self._sandbox, function_to_run=self._function_to_run, function_to_evolve=self._function_to_evolve, full_inputs=self._inputs, fingerprint_inputs=self._fingerprint_inputs, timeout_seconds=self._fingerprint_timeout_seconds)
                    # Register with the calculated score
                    self._duplicate_checker.register_program(ast_hash, fingerprint_hash, final_score)
            else:
                # Full evaluation failed
                final_scores_per_test = None
                final_score = None


        # 5. Register Results (or failure) with Database and Profiler
        total_processing_time = total_check_time + total_evaluate_time

        if final_scores_per_test is not None and final_score is not None:
            # Register successful program (either new or cached/validated)
            self._database.register_program(
                program=new_function,
                island_id=island_id,
                scores_per_test=final_scores_per_test, # Pass actual or dummy scores dict
                # --- Pass additional info ---
                profiler=self._profiler_instance,
                global_sample_nums=global_sample_nums,
                sample_time=sample_time,
                evaluate_time=total_processing_time, # Combined time
                is_cached_duplicate=processed_as_cache_hit
            )
        else:
            # Register failure (compile fail handled earlier, this covers eval/AST hit/validation fail)
            if self._profiler_instance:
                new_function.score = None # Ensure score is None
                new_function.evaluate_time = total_processing_time
                # Pass cache hit status even for failures if it originated as one
                self._profiler_instance.register_function(new_function, is_cached_duplicate=processed_as_cache_hit)